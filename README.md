# LogAnalyzer

## Описание проекта

**LogAnalyzer** — это утилита для анализа лог-файлов серверов (например, NGINX). Программа позволяет
быстро и эффективно собирать статистику по логам, используя потоковую обработку данных, что снижает
потребление памяти и позволяет обрабатывать большие объемы данных без необходимости загружать весь
файл в оперативную память. Анализ включает подсчет запросов, наиболее популярные ресурсы, распределение
по кодам ответа, средний размер ответа и другие метрики.

## Основные возможности

- **Потоковая обработка данных:** Обработка логов без полной загрузки в память, что позволяет работать
с большими файлами.
- **Анализ временного диапазона:** Поддержка параметров `from` и `to` для фильтрации по дате и времени.
- **Фильтрация по полям:** Возможность фильтровать логи по значениям, например, `method` или `agent`.
- **Форматы отчетов:** Генерация отчетов в форматах Markdown и AsciiDoc.
- **Поддержка локальных и удаленных логов:** Возможность работать с логами по URL или локальному пути.

## Примеры запуска программы

### Простой запуск с локальным файлом

```bash
java -jar target/log-analyzer-1.0-SNAPSHOT.jar -f ./logs/nginx_logs.txt -r markdown
```

### Запуск с анализом временного диапазона

```bash
java -jar target/log-analyzer-1.0-SNAPSHOT.jar -f ./logs/nginx_logs.txt -from "2015-05-01T00:00:00Z" -to "2015-05-30T23:59:59Z" -filter-field "method" -filter-value "GET"
```

### Фильтрация по HTTP методу

```bash
java -jar target/log-analyzer-1.0-SNAPSHOT.jar -f ./logs/nginx_logs.txt -filter-field "method" -filter-value "GET"
```

### Поддержка URL для загрузки логов

```bash
java -jar target/log-analyzer-1.0-SNAPSHOT.jar -f https://example.com/nginx_logs.txt -r markdown
```

## Основные компоненты и методы

### 1. Класс `LogLauncher` и метод `analyzeLogFile`

Метод `analyzeLogFile` отвечает за основную логику анализа логов. Он использует потоковую обработку данных, что
позволяет обрабатывать логи как из локальных файлов, так и из URL. Этот подход предотвращает загрузку всего файла в
память, что особенно полезно для больших логов. Вместо этого, строки читаются и анализируются построчно, используя
стримы Java.

### 2. Класс `LogStatistics`

Этот класс собирает статистику по логам. Он поддерживает:
- Подсчет общего числа запросов
- Определение наиболее часто запрашиваемых ресурсов
- Определение распределения по кодам ответов
- Расчет среднего и 95-процентного размера ответа
- Распределение запросов по часам и IP-адресам

### 3. Класс `LogFilter`

Содержит методы для фильтрации логов:

- **Фильтрация по времени:** Учитывает параметры `from` и `to`, чтобы анализировать логи только
  в указанном диапазоне.
- **Фильтрация по полям:** Возможность фильтровать логи по значениям, например,
  по HTTP методу (`GET`, `POST`), IP-адресу или User-Agent.

### 4. Класс `LogParser`

Отвечает за парсинг строк из логов и преобразование их в объекты LogEntry. Он учитывает структуру
стандартных логов NGINX и поддерживает обработку различных форматов строк.

Основные возможности:

- **Поддержка двух форматов дат:** Класс LogParser может обрабатывать даты в формате ISO8601 и
  в старом формате `dd/MMM/yyyy:HH:mm:ss Z`. Это обеспечивает гибкость и совместимость с различными
  форматами логов.
- **Гибкость и контроль:** Написание собственного парсера позволяет полностью контролировать процесс
  парсинга и легко адаптировать его под специфические требования проекта.
- **Обработка исключений:** Класс LogParser корректно обрабатывает исключения, возникающие
  при парсинге дат, что делает его надежным инструментом для анализа логов.

### 5. Форматирование отчетов

Программа поддерживает два формата отчетов:
- **Markdown:** Используется для простого и читабельного формата документации.
- **AsciiDoc:** Предоставляет больше возможностей форматирования и полезен для создания
  более сложных отчетов.

Отчеты формируются через интерфейс `ReportFormatter`, что позволяет легко добавлять новые форматы
при необходимости.

## Примеры результатов

### Пример отчета в формате AsciiDoc:

```asciidoc
== General Information

|===
|Metric |Value |
|File(s) |./logs/nginx_logs.txt | 
|Start Date |2015-05-17 |
|End Date |2015-06-04 |
|Total Requests |51462 |
|Average Response Size |659509.51 b|
|95th Percentile Response Size |1768 b|
|===
```

### Запуск программы

```bash
java -jar target/log-analyzer-1.0-SNAPSHOT.jar -f ./logs/nginx_logs.txt
```

## Дополнительные параметры

- **`-f` или `--file`**: Указывает путь к лог-файлу или URL.
- **`-from` и `-to`**: Опциональные параметры для фильтрации по времени в формате ISO8601.
- **`-r` или `--report`**: Указывает формат отчета (markdown или asciidoc).
- **`-filter-field` и `-filter-value`**: Указывают поле и значение для фильтрации логов.

## Тестирование

### Основные тесты включают:

1. **Проверка чтения и анализа локальных файлов и URL.**
2. **Тестирование парсинга строк логов.**
3. **Проверка работы фильтрации по времени и значениям.**
4. **Валидация форматов отчетов Markdown и AsciiDoc.**

## Заключение

**LogAnalyzer** — мощный инструмент для анализа логов серверов. Благодаря потоковой обработке данных
и поддержке гибкой фильтрации, он позволяет обрабатывать большие объемы логов, создавая
структурированные отчеты в удобных форматах.

## Сборка и тестирование

Запустите команду для полной сборки и проверки проекта:

```bash
mvn clean verify
```

Для Unix (Linux, macOS, Cygwin, WSL):

```bash
./mvnw clean verify
```

Для Windows:

```bash
mvnw.cmd clean verify
```

## Дополнительные материалы

- [Документация по Maven](https://maven.apache.org/guides/index.html)
- [Поиск зависимостей и их версий](https://central.sonatype.com/search)
- [Javadoc для Java 22](https://docs.oracle.com/en/java/javase/22/docs/api/index.html)

[course-url]: https://edu.tinkoff.ru/all-activities/courses/870efa9d-7067-4713-97ae-7db256b73eab
